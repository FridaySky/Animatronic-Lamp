# Animatronic-Lamp
This repository is dedicated to our group project for Senior Design.

The objective is to modify a physical Luxo lamp to be capable of conveying emotions through movement. This animatronic lamp shall be capable of movement and interaction with human users via speech recognition and object tracking. The aim is to provide a dynamic and unique lighting solution.

## Getting Started

### Prerequisites

### Installation

## Running the Tests

## Deployment

## Built With

### Hardware
* Circline LED Bulb
* Logitech Webcam
* [Raspberry Pi 3](https://www.raspberrypi.org/) - The brains of this lamp
* 5 Servomotors

### Software
* [Processing](https://processing.org/) - Simulation of the lamp's joint movements
* [Python](https://www.python.org/) - Programming language used to program the animatronic lamp
* [Google Assistant API](https://console.cloud.google.com/apis/library/embeddedassistant.googleapis.com/) - Speech recognition and speech synthesis
* [OpenCV](https://opencv.org/) - Computer vision library for face recognition, object detection, and object tracking
* [TensorFlow](https://www.tensorflow.org/) - Machine learning framework for training the lamp's joint movements

## Repository Directories
* *Documentation* contains all block diagrams, design documents, proposals, and presentation files.

## Authors
* Ian Lasky - imlasky
* Timothy Allen - TimothyA86
* Raphael Miller - gemini88mill
* Joshua Schroeder - ???
* Kevin Tran - FridaySky

## Acknowledgments
* Disney's Pixar Lamp for providing the inspiration for this project.
* Dr. Mark Heinrich for allowing us to proceed with this idea as our Senior Design project, and also for facilitating the formation of this group as well as providing guidance for the project documentation.
